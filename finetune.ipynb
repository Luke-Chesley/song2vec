{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from config import Wav2Vec2Config\n",
    "from model import Wav2Vec2ForPreTraining,Wav2Vec2ForSequenceClassification,Wav2Vec2GumbelVectorQuantizer,_compute_mask_indices,Wav2Vec2Encoder,Wav2Vec2FeatureProjection\n",
    "\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices, _sample_negative_indices\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from dataset import AudioDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parent_dir = 'data/mp3_train_files'\n",
    "file_list = [os.path.join(root, file) \n",
    "             for root, _, files in os.walk(parent_dir) \n",
    "             for file in files]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(file_list)\n",
    "\n",
    "train_size = int(0.8 * len(file_list))\n",
    "val_size = int(0.1 * len(file_list))\n",
    "test_size = len(file_list) - train_size - val_size\n",
    "\n",
    "train_files = file_list[:train_size]\n",
    "val_files = file_list[train_size:train_size + val_size]\n",
    "test_files = file_list[train_size + val_size:]\n",
    "\n",
    "train_dataset = AudioDataset(train_files)\n",
    "val_dataset = AudioDataset(val_files)\n",
    "test_dataset = AudioDataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('weights/pre_train-01.pt')\n",
    "config = Wav2Vec2Config()\n",
    "pre_train_model = Wav2Vec2ForPreTraining(config)\n",
    "pre_train_model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "model = Wav2Vec2ForSequenceClassification(pre_train_model,len(train_dataset.labels()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_2_label = train_dataset.id_2_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Crochet', 'Ishizaka')\n",
      "('Crochet', 'Rubinstein')\n",
      "('Crochet', 'Horowitz')\n",
      "('Crochet', 'Nikolayeva')\n",
      "('Crochet', 'Tureck')\n",
      "('Ishizaka', 'Tharaud')\n",
      "('Ishizaka', 'Gould')\n",
      "('Crochet', 'Rubinstein')\n",
      "('Crochet', 'Horowitz')\n",
      "('Ishizaka', 'Schiff')\n",
      "('Crochet', 'Gould')\n",
      "('Crochet', 'Moravec')\n",
      "('Crochet', 'Nikolayeva')\n",
      "('Crochet', 'Tureck')\n",
      "('Ishizaka', 'Moravec')\n",
      "('Crochet', 'Crochet')\n",
      "('Crochet', 'Tureck')\n",
      "('Crochet', 'Crochet')\n",
      "('Crochet', 'Rubinstein')\n",
      "('Crochet', 'Rubinstein')\n",
      "('Crochet', 'Tharaud')\n",
      "('Crochet', 'Nikolayeva')\n",
      "('Ishizaka', 'Tureck')\n",
      "('Crochet', 'Moravec')\n",
      "('Crochet', 'Richter')\n",
      "('Crochet', 'Rubinstein')\n",
      "('Crochet', 'Tureck')\n",
      "('Crochet', 'Gould')\n",
      "('Crochet', 'Richter')\n",
      "('Nikolayeva', 'Gould')\n",
      "('Crochet', 'Crochet')\n",
      "('Crochet', 'Tureck')\n",
      "('Crochet', 'Richter')\n",
      "('Crochet', 'Nikolayeva')\n",
      "('Crochet', 'Tureck')\n",
      "('Ishizaka', 'Richter')\n",
      "('Crochet', 'Gould')\n",
      "('Ishizaka', 'Tharaud')\n",
      "('Crochet', 'Rubinstein')\n",
      "('Crochet', 'Crochet')\n",
      "('Crochet', 'Ishizaka')\n",
      "('Crochet', 'Tureck')\n",
      "('Crochet', 'Richter')\n",
      "('Crochet', 'Ishizaka')\n",
      "('Crochet', 'Nikolayeva')\n",
      "('Crochet', 'Crochet')\n",
      "('Crochet', 'Rubinstein')\n",
      "('Crochet', 'Rubinstein')\n",
      "('Crochet', 'Horowitz')\n",
      "('Crochet', 'Rubinstein')\n"
     ]
    }
   ],
   "source": [
    "sm = nn.Softmax(dim=-1)\n",
    "\n",
    "for N in range(50):\n",
    "\n",
    "    out = model(test_dataset[N][0].unsqueeze(0)).squeeze()\n",
    "\n",
    "    pred = id_2_label[sm(out).argmax().item()]\n",
    "\n",
    "    label = test_dataset[N][1]\n",
    "\n",
    "    print((pred,label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm(out).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
