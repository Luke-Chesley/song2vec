{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from config import Wav2Vec2Config\n",
    "from model import Wav2Vec2ForPreTraining,Wav2Vec2FeatureEncoder,Wav2Vec2GumbelVectorQuantizer,_compute_mask_indices,Wav2Vec2Encoder,Wav2Vec2FeatureProjection\n",
    "\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices, _sample_negative_indices\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "\n",
    "from dataset import AudioDataset\n",
    "\n",
    "\n",
    "\n",
    "parent_dir = 'data/mp3_train_files'\n",
    "file_list = [os.path.join(root, file) \n",
    "             for root, _, files in os.walk(parent_dir) \n",
    "             for file in files]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(file_list)\n",
    "\n",
    "train_size = int(0.8 * len(file_list))\n",
    "val_size = int(0.1 * len(file_list))\n",
    "test_size = len(file_list) - train_size - val_size\n",
    "\n",
    "train_files = file_list[:train_size]\n",
    "val_files = file_list[train_size:train_size + val_size]\n",
    "test_files = file_list[train_size + val_size:]\n",
    "\n",
    "train_dataset = AudioDataset(train_files)\n",
    "val_dataset = AudioDataset(val_files)\n",
    "test_dataset = AudioDataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Wav2Vec2Config()\n",
    "model = Wav2Vec2ForPreTraining(config)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "num_training_steps = 400000  \n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.08 * num_training_steps),\n",
    "    num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19780352"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 00: 100%|██████████| 2067/2067 [04:30<00:00,  7.63it/s, contrastive_loss=369, loss=543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 543.2560056881105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 01: 100%|██████████| 2067/2067 [04:30<00:00,  7.64it/s, contrastive_loss=346, loss=544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Loss: 543.8089731158296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 02: 100%|██████████| 2067/2067 [04:18<00:00,  8.01it/s, contrastive_loss=369, loss=544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Loss: 543.8050731406099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 03: 100%|██████████| 2067/2067 [04:14<00:00,  8.11it/s, contrastive_loss=369, loss=544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Loss: 543.5762296767989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 04: 100%|██████████| 2067/2067 [04:14<00:00,  8.12it/s, contrastive_loss=369, loss=544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Loss: 543.6875189129257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 05: 100%|██████████| 2067/2067 [04:14<00:00,  8.11it/s, contrastive_loss=369, loss=544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Loss: 543.7317823346364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 06: 100%|██████████| 2067/2067 [04:15<00:00,  8.11it/s, contrastive_loss=369, loss=543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Loss: 543.3108848715729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 07: 100%|██████████| 2067/2067 [04:14<00:00,  8.12it/s, contrastive_loss=369, loss=544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Loss: 543.7758012761456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 08: 100%|██████████| 2067/2067 [04:14<00:00,  8.11it/s, contrastive_loss=369, loss=543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Loss: 543.4434387472787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 09: 100%|██████████| 2067/2067 [04:15<00:00,  8.10it/s, contrastive_loss=369, loss=544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Loss: 544.0651899170749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 10: 100%|██████████| 2067/2067 [04:14<00:00,  8.11it/s, contrastive_loss=369, loss=544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Loss: 544.3112778352203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 11: 100%|██████████| 2067/2067 [04:14<00:00,  8.11it/s, contrastive_loss=337, loss=543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Loss: 543.3707131439785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 12: 100%|██████████| 2067/2067 [04:14<00:00,  8.11it/s, contrastive_loss=355, loss=543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Loss: 543.4667995916108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 13: 100%|██████████| 2067/2067 [04:15<00:00,  8.10it/s, contrastive_loss=369, loss=543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Loss: 543.3930338807422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 14: 100%|██████████| 2067/2067 [04:23<00:00,  7.83it/s, contrastive_loss=369, loss=543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Loss: 543.1307846386766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 15:   0%|          | 0/2067 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m batch_iterator \u001b[38;5;241m=\u001b[39m tqdm(data_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_iterator):\n\u001b[1;32m     14\u001b[0m     input_values \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#      extract_features = model.wav2vec2.feature_extractor(input_values).transpose(1,2)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#      seq_len = extract_features.size(1)  # Sequence length after feature extraction\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/jupyterlab/Notebooks/song2vec/venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/jupyterlab/Notebooks/song2vec/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/jupyterlab/Notebooks/song2vec/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/jupyterlab/Notebooks/song2vec/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1085\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1083\u001b[0m _utils\u001b[38;5;241m.\u001b[39msignal_handling\u001b[38;5;241m.\u001b[39m_set_SIGCHLD_handler()\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_pids_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/jupyterlab/Notebooks/song2vec/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1118\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;66;03m# prime the prefetch loop\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefetch_factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers):\n\u001b[0;32m-> 1118\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_put_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/jupyterlab/Notebooks/song2vec/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1363\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;66;03m# not found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_queues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mworker_queue_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_idx] \u001b[38;5;241m=\u001b[39m (worker_queue_idx,)\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:94\u001b[0m, in \u001b[0;36mQueue.put\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_notempty:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_thread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mappend(obj)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_notempty\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:177\u001b[0m, in \u001b[0;36mQueue._start_thread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    176\u001b[0m debug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoing self._thread.start()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m debug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m... done self._thread.start()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joincancelled:\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:940\u001b[0m, in \u001b[0;36mThread.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m _limbo[\u001b[38;5;28mself\u001b[39m]\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 940\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_started\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "output_attentions = True\n",
    "output_hidden_states = False\n",
    "return_dict = torch.BoolTensor(1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    batch_iterator = tqdm(data_loader, desc=f\"Processing Epoch {epoch:02d}\")\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_idx, batch in enumerate(batch_iterator):\n",
    "        input_values = batch[0].to(device)\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #      extract_features = model.wav2vec2.feature_extractor(input_values).transpose(1,2)\n",
    "        #      seq_len = extract_features.size(1)  # Sequence length after feature extraction\n",
    "\n",
    "        seq_len = 249\n",
    "        attention_mask = torch.ones((input_values.size(0), seq_len), dtype=torch.long, device=device)\n",
    "\n",
    "        mask_time_indices = _compute_mask_indices(\n",
    "            shape=(input_values.size(0), seq_len),\n",
    "            mask_prob=config.mask_time_prob,\n",
    "            mask_length=config.mask_time_length,\n",
    "            attention_mask=attention_mask,\n",
    "            min_masks=config.mask_time_min_masks\n",
    "        )\n",
    "\n",
    "        sampled_negative_indices = _sample_negative_indices(\n",
    "            features_shape=(input_values.size(0), seq_len),\n",
    "            num_negatives=model.config.num_negatives,\n",
    "            mask_time_indices=mask_time_indices,\n",
    "        )\n",
    "\n",
    "        mask_time_indices = torch.tensor(mask_time_indices, device=device, dtype=torch.bool)\n",
    "        sampled_negative_indices = torch.tensor(sampled_negative_indices, device=device)\n",
    "\n",
    "    \n",
    "\n",
    "        out = model(input_values=input_values,\n",
    "        attention_mask=attention_mask,\n",
    "        mask_time_indices=mask_time_indices,\n",
    "        sampled_negative_indices=sampled_negative_indices,\n",
    "        output_attentions=output_attentions,\n",
    "        output_hidden_states=output_hidden_states,\n",
    "        return_dict=return_dict)\n",
    "\n",
    "        \n",
    "\n",
    "        loss = out.loss\n",
    "        contrastive_loss = out.contrastive_loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        batch_iterator.set_postfix(loss=total_loss / (batch_idx + 1),contrastive_loss=contrastive_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_out = model.wav2vec2(test_dataset[0][0].to(device).unsqueeze(0)).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'weights/pre_train-19.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example pretraining \n",
    "https://github.com/huggingface/transformers/blob/main/examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
