{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoFeatureExtractor, Wav2Vec2ForPreTraining,get_scheduler\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices, _sample_negative_indices\n",
    "#from transformers.models.wav2vec2.feature_extraction_wav2vec2 import Wav2Vec2FeatureExtractor\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import math\n",
    "\n",
    "from model import Wav2Vec2ForPreTraining,Wav2Vec2Config,Wav2Vec2FeatureExtractor\n",
    "from dataset import AudioDatasetSplits\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_train = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "feature_extractor = Wav2Vec2FeatureExtractor()\n",
    "config = Wav2Vec2Config()\n",
    "model = Wav2Vec2ForPreTraining(config).to(device)\n",
    "ds_train = AudioDatasetSplits().train\n",
    "#ds_val = AudioDatasetSplits().val\n",
    "\n",
    "# ips = feature_extractor(ds_train[0]['audio'],return_tensors='pt',sampling_rate=ds_train[0]['sample_rate']).input_values\n",
    "# batch_size, raw_sequence_length = ips.shape\n",
    "# sequence_length = model._get_feat_extract_output_lengths(raw_sequence_length).item()\n",
    "\n",
    "# mask_time_indices = _compute_mask_indices(\n",
    "#     shape=(batch_size, sequence_length), mask_prob=model.config.mask_time_prob, mask_length=model.config.mask_time_length\n",
    "# )\n",
    "\n",
    "# sampled_negative_indices = _sample_negative_indices(\n",
    "#     features_shape=(batch_size, sequence_length),\n",
    "#     num_negatives=model.config.num_negatives,\n",
    "#     mask_time_indices=mask_time_indices,\n",
    "# )\n",
    "\n",
    "# mask_time_indices = torch.tensor(data=mask_time_indices, device=ips.device, dtype=torch.long)\n",
    "# sampled_negative_indices = torch.tensor(\n",
    "#     data=sampled_negative_indices, device=ips.device, dtype=torch.long\n",
    "# )\n",
    "\n",
    "# model = model.train()\n",
    "# loss = model(\n",
    "#     ips, mask_time_indices=mask_time_indices, sampled_negative_indices=sampled_negative_indices\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad_norm(params, scale=1):\n",
    "    \"\"\"Compute grad norm given a gradient scale.\"\"\"\n",
    "    total_norm = 0.0\n",
    "    for p in params:\n",
    "        if p.grad is not None:\n",
    "            param_norm = (p.grad.detach().data / scale).norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm**0.5\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train,batch_size=1) # can put feature extractor in ds\n",
    "#dl_val = DataLoader(ds_val,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3817e-06, 2.2483e-06, 1.8022e-06,  ..., 2.3067e-01, 2.1962e-01,\n",
       "         2.2706e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl_train))['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_accumulation_steps = 1\n",
    "logging_steps = 10\n",
    "max_gumbel_temperature = 2.0\n",
    "min_gumbel_temperature = 0.5\n",
    "gumbel_temperature_decay = 0.999995\n",
    "num_train_epochs = 1\n",
    "num_update_steps_per_epoch = math.ceil(len(dl_train) / gradient_accumulation_steps)\n",
    "\n",
    "max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.999\n",
    "adam_epsilon = 1e-8\n",
    "optimizer = AdamW(\n",
    "        list(model.parameters()),\n",
    "        lr=5e-2,\n",
    "        betas=[adam_beta1, adam_beta2],\n",
    "        eps=adam_epsilon,\n",
    "    )\n",
    "\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "        name='linear',\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=110,\n",
    "        num_training_steps=max_train_steps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>) torch.Size([498, 320])\n",
      "tensor([[[0.0029, 0.0036, 0.0047,  ..., 0.0016, 0.0011, 0.0037],\n",
      "         [0.0036, 0.0036, 0.0037,  ..., 0.0043, 0.0046, 0.0025]],\n",
      "\n",
      "        [[0.0055, 0.0026, 0.0021,  ..., 0.0017, 0.0067, 0.0022],\n",
      "         [0.0039, 0.0036, 0.0068,  ..., 0.0030, 0.0031, 0.0014]],\n",
      "\n",
      "        [[0.0038, 0.0032, 0.0073,  ..., 0.0010, 0.0044, 0.0014],\n",
      "         [0.0038, 0.0030, 0.0043,  ..., 0.0036, 0.0014, 0.0013]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0034, 0.0022, 0.0030,  ..., 0.0038, 0.0026, 0.0047],\n",
      "         [0.0032, 0.0043, 0.0018,  ..., 0.0055, 0.0050, 0.0026]],\n",
      "\n",
      "        [[0.0020, 0.0073, 0.0053,  ..., 0.0029, 0.0025, 0.0017],\n",
      "         [0.0027, 0.0029, 0.0032,  ..., 0.0010, 0.0028, 0.0014]],\n",
      "\n",
      "        [[0.0024, 0.0056, 0.0038,  ..., 0.0008, 0.0062, 0.0027],\n",
      "         [0.0023, 0.0042, 0.0058,  ..., 0.0032, 0.0014, 0.0031]]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>) torch.Size([249, 2, 320])\n",
      "tensor(622.0139, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>) torch.Size([249, 640])\n",
      "tensor([[[-0., 0., -0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., 0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., -0.,  ..., -0., -0., 0.],\n",
      "         ...,\n",
      "         [-0., 0., 0.,  ..., -0., 0., 0.],\n",
      "         [-0., 0., -0.,  ..., -0., 0., 0.],\n",
      "         [0., -0., 0.,  ..., 0., -0., 0.]],\n",
      "\n",
      "        [[-0., 0., -0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., 0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., -0.,  ..., -0., -0., 0.],\n",
      "         ...,\n",
      "         [-0., 0., 0.,  ..., -0., 0., 0.],\n",
      "         [-0., 0., -0.,  ..., -0., 0., 0.],\n",
      "         [0., -0., 0.,  ..., 0., -0., 0.]],\n",
      "\n",
      "        [[-0., 0., -0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., 0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., -0.,  ..., -0., -0., 0.],\n",
      "         ...,\n",
      "         [-0., 0., 0.,  ..., -0., 0., 0.],\n",
      "         [-0., 0., -0.,  ..., -0., 0., 0.],\n",
      "         [0., -0., 0.,  ..., 0., -0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0., 0., -0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., 0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., -0.,  ..., -0., -0., 0.],\n",
      "         ...,\n",
      "         [-0., 0., 0.,  ..., -0., 0., 0.],\n",
      "         [-0., 0., -0.,  ..., -0., 0., 0.],\n",
      "         [0., -0., 0.,  ..., 0., -0., 0.]],\n",
      "\n",
      "        [[-0., 0., -0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., 0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., -0.,  ..., -0., -0., 0.],\n",
      "         ...,\n",
      "         [-0., 0., 0.,  ..., -0., 0., 0.],\n",
      "         [-0., 0., -0.,  ..., -0., 0., 0.],\n",
      "         [0., -0., 0.,  ..., 0., -0., 0.]],\n",
      "\n",
      "        [[-0., 0., -0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., 0.,  ..., -0., -0., -0.],\n",
      "         [-0., 0., -0.,  ..., -0., -0., 0.],\n",
      "         ...,\n",
      "         [-0., 0., 0.,  ..., -0., 0., 0.],\n",
      "         [-0., 0., -0.,  ..., -0., 0., 0.],\n",
      "         [0., -0., 0.,  ..., 0., -0., 0.]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>) torch.Size([249, 640, 128])\n",
      "tensor([[[ 0.0022,  0.0014,  0.0095,  ..., -0.0033, -0.0003,  0.0014],\n",
      "         [ 0.0046,  0.0037, -0.0013,  ...,  0.0033,  0.0046, -0.0102],\n",
      "         [-0.0008,  0.0021,  0.0102,  ..., -0.0047, -0.0016, -0.0008],\n",
      "         ...,\n",
      "         [-0.0037,  0.0001, -0.0076,  ..., -0.0158, -0.0154,  0.0032],\n",
      "         [-0.0057, -0.0043, -0.0064,  ..., -0.0029,  0.0012,  0.0002],\n",
      "         [-0.0040, -0.0024, -0.0045,  ...,  0.0014, -0.0063,  0.0053]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "start_epochs = 0\n",
    "completed_steps = 0\n",
    "progress_bar = tqdm(range(max_train_steps),disable=True)\n",
    "\n",
    "for epoch in range(start_epochs,num_train_epochs):\n",
    "    model.train()\n",
    "    #batch_iterator = tqdm(dl_train,desc=f\"Processing Epoch {epoch:02d}\")\n",
    "    for batch_idx,batch in enumerate(dl_train):\n",
    "\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "\n",
    "      #  ips = feature_extractor(batch['audio']['array'],sampling_rate=16000,return_tensors='pt').input_values.squeeze(0).to(device)\n",
    "\n",
    "\n",
    "\n",
    "       # print(batch['audio'].shape)\n",
    "        ips = feature_extractor(batch['audio'],sampling_rate=batch['sample_rate'][0],return_tensors='pt').input_values.squeeze(0).to(device)\n",
    "        #print(ips.shape)\n",
    "\n",
    "        batch_size,raw_sequence_length = ips.shape\n",
    "\n",
    "        sequence_length = model._get_feat_extract_output_lengths(raw_sequence_length).item()\n",
    "\n",
    "\n",
    "        mask_time_indices = _compute_mask_indices(\n",
    "            shape=(batch_size, sequence_length), mask_prob=model.config.mask_time_prob, mask_length=model.config.mask_time_length\n",
    "        )\n",
    "\n",
    "        sampled_negative_indices = _sample_negative_indices(\n",
    "            features_shape=(batch_size, sequence_length),\n",
    "            num_negatives=model.config.num_negatives,\n",
    "            mask_time_indices=mask_time_indices,\n",
    "        )\n",
    "\n",
    "        mask_time_indices = torch.tensor(data=mask_time_indices, device=ips.device, dtype=torch.long)\n",
    "        sampled_negative_indices = torch.tensor(\n",
    "            data=sampled_negative_indices, device=ips.device, dtype=torch.long\n",
    "        )\n",
    "\n",
    "       #print(ips)\n",
    "       # print(mask_time_indices)\n",
    "       # print(sampled_negative_indices)\n",
    "\n",
    "        outputs = model(ips,mask_time_indices=mask_time_indices,sampled_negative_indices=sampled_negative_indices)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "       # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=4.0)\n",
    "\n",
    "        if (batch_idx + 1) % gradient_accumulation_steps == 0 or batch_idx == len(dl_train) - 1:\n",
    "                grad_norm = get_grad_norm(model.parameters(), 1)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        gumbel_temperature = max(\n",
    "                    max_gumbel_temperature * gumbel_temperature_decay**completed_steps,\n",
    "                    min_gumbel_temperature,\n",
    "                )\n",
    "        \n",
    "        model.set_gumbel_temperature(gumbel_temperature)\n",
    "\n",
    "        completed_steps += 1\n",
    "\n",
    "        # 6. Log all results\n",
    "        if (batch_idx + 1) % (gradient_accumulation_steps * logging_steps) == 0:\n",
    "            loss.detach()\n",
    "            outputs.contrastive_loss.detach()\n",
    "            outputs.diversity_loss.detach()\n",
    "\n",
    "            train_logs = {\n",
    "                \"loss\": (loss * gradient_accumulation_steps) ,\n",
    "                \"constrast_loss\": outputs.contrastive_loss ,\n",
    "                \"div_loss\": outputs.diversity_loss ,\n",
    "                \"ppl\": outputs.codevector_perplexity,\n",
    "                \"lr\": torch.tensor(optimizer.param_groups[0][\"lr\"]),\n",
    "                \"temp\": torch.tensor(gumbel_temperature),\n",
    "                \"grad_norm\": torch.tensor(grad_norm),\n",
    "            }\n",
    "            log_str = \"\"\n",
    "            for k, v in train_logs.items():\n",
    "                log_str += \"| {}: {:.3e}\".format(k, v.item())\n",
    "\n",
    "            progress_bar.write(log_str)\n",
    "\n",
    "            break\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #print('loss',loss)\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "        #batch_iterator.set_postfix(loss=running_loss /( 1 if batch_idx == 0 else batch_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3846610266.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    ------------------------------------------------------------------\u001b[0m\n\u001b[0m                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "audio = 1, 80000\n",
    "tensor([[1.3817e-06, 2.2483e-06, 1.8022e-06,  ..., 2.3067e-01, 2.1962e-01,\n",
    "         2.2706e-01]], device='cuda:0')\n",
    "------------------------------------------------------------------\n",
    "\n",
    "ips = 1, 80000 \n",
    "tensor([[2.2682e-04, 2.3256e-04, 2.2961e-04,  ..., 1.5293e+00, 1.4560e+00,\n",
    "         1.5053e+00]], device='cuda:0')\n",
    "------------------------------------------------------------------\n",
    "\n",
    "extract_features = 1,249,512\n",
    "tensor([[[ 0.1235,  1.0637,  0.3155,  ...,  0.1192, -0.0555,  0.3207],\n",
    "         [-0.0291, -0.0841, -0.1173,  ..., -0.0075,  0.0098, -0.0437],\n",
    "         [ 0.1854, -0.1252,  0.4169,  ...,  0.0302, -0.1354,  0.0635],\n",
    "         ...,\n",
    "         [-0.0499, -0.1683, -0.0749,  ..., -0.0380,  0.0608,  0.0732],\n",
    "         [ 0.1800,  0.1400,  2.0366,  ...,  0.0052,  0.1235,  0.0312],\n",
    "         [ 0.0764,  0.1193,  0.6772,  ...,  0.0497,  0.1072,  0.0665]]],\n",
    "       device='cuda:0', grad_fn=<GeluBackward0>)\n",
    "------------------------------------------------------------------\n",
    "hidden_states = 1,249,768\n",
    "tensor([[[ 0.0339, -0.4830, -0.0305,  ...,  0.0159,  0.0779, -0.2026],\n",
    "         [ 0.2883, -0.7021,  0.6997,  ...,  0.5885,  0.3514,  0.1212],\n",
    "         [-0.2194, -0.4437,  0.2657,  ..., -0.2675, -0.3728, -0.4760],\n",
    "         ...,\n",
    "         [-0.4071, -0.5601, -0.1708,  ..., -0.6891, -0.8761,  0.1655],\n",
    "         [-0.2948, -0.3244,  0.1004,  ...,  0.0792,  0.1473, -0.1143],\n",
    "         [-0.0085,  0.3465,  0.3159,  ...,  0.7847, -0.2695,  0.7689]]],\n",
    "       device='cuda:0', grad_fn=<ViewBackward0>) \n",
    "------------------------------------------------------------------\n",
    "extract_features = 1,249,512\n",
    "tensor([[[-0.9377, -0.0026,  0.2004,  ...,  1.1388, -1.0242,  0.4582],\n",
    "         [-0.8192, -0.6528, -0.4071,  ..., -0.6667,  0.5033, -0.5041],\n",
    "         [-0.3353,  0.6557,  1.2236,  ..., -0.5683,  0.2599,  0.5061],\n",
    "         ...,\n",
    "         [ 0.2780, -0.0862,  0.7484,  ..., -0.8934,  1.6097, -0.2075],\n",
    "         [-1.7482,  0.5112,  0.4290,  ...,  1.2316, -0.8526, -0.3602],\n",
    "         [-0.2306,  0.0931,  0.1837,  ...,  0.0942, -0.6955, -1.0463]]],\n",
    "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>) \n",
    "------------------------------------------------------------------\n",
    "\n",
    "hidden_states = 1,249, 768\n",
    "tensor([[[-0.1991,  0.3561,  0.1502,  ...,  0.0869,  0.6993,  0.1601],\n",
    "         [ 0.9603,  0.2272, -0.1970,  ...,  0.2197,  0.0703, -0.3534],\n",
    "         [-0.0289,  0.0383, -0.1532,  ...,  0.4002,  0.6341, -0.0135],\n",
    "         ...,\n",
    "         [ 0.0797, -0.0814,  0.6674,  ...,  0.1392,  0.4300, -0.2692],\n",
    "         [-0.3952, -0.6119, -0.5780,  ...,  0.7492,  0.2148,  0.2660],\n",
    "         [ 0.7736, -0.1803, -0.1786,  ..., -0.3715, -0.1962, -0.0951]]],\n",
    "------------------------------------------------------------------\n",
    "\n",
    "encoder_outputs (last hidden state) = [1, 249, 768])\n",
    "tensor([[[ 1.8529,  1.2018,  1.2603,  ..., -0.4005, -0.7679,  1.5168],\n",
    "         [ 2.4584,  0.3279,  1.1077,  ...,  0.0198,  0.5620,  1.3509],\n",
    "         [ 0.8397,  1.1146,  1.2582,  ...,  0.7337,  0.1549,  0.1386],\n",
    "         ...,\n",
    "         [ 2.3995,  0.0749,  0.3688,  ...,  0.1632, -0.3292,  0.8795],\n",
    "         [ 2.0309,  1.2241,  2.5985,  ..., -0.2022,  1.0152,  0.7052],\n",
    "         [-0.0648,  0.1555,  0.9045,  ...,  0.6808,  1.3329, -1.1029]]],\n",
    "------------------------------------------------------------------ <- pretraining model\n",
    "\n",
    "transformer_features = 1, 249, 256\n",
    "tensor([[[ 0.4395,  0.0093,  0.1106,  ...,  0.1624, -0.4259, -0.1438],\n",
    "         [ 0.2835,  0.0836, -0.1176,  ..., -1.4001, -0.6082, -0.4137],\n",
    "         [ 0.1038, -0.6754,  0.0953,  ...,  0.0870, -0.5074, -0.2045],\n",
    "         ...,\n",
    "         [ 0.7046, -0.7818, -0.0214,  ...,  0.1316, -0.0481, -0.3063],\n",
    "         [-0.4119,  0.0397,  0.2056,  ...,  0.2657,  0.0776,  0.1673],\n",
    "         [ 0.5931, -0.5297,  0.2475,  ..., -1.0861, -0.2295,  1.0191]]],\n",
    "       device='cuda:0', grad_fn=<ViewBackward0>) \n",
    "------------------------------------------------------------------\n",
    "\n",
    "extract_features = 1, 249, 512\n",
    "tensor([[[-0.5587, -1.2472, -1.0980,  ...,  0.8418, -0.5749,  0.4490],\n",
    "         [-0.7627, -0.4484, -0.7772,  ..., -0.2958,  1.2044, -0.6321],\n",
    "         [-0.8375, -0.0000, -0.9049,  ..., -0.9059,  0.1687, -0.6254],\n",
    "         ...,\n",
    "         [-0.0000, -0.0000, -2.3028,  ..., -0.5176,  3.0487, -0.0000],\n",
    "         [-1.0692, -0.0000, -0.8404,  ..., -0.3041,  1.6150, -0.0000],\n",
    "         [-0.0000,  0.0000, -0.4952,  ..., -0.0000,  2.0064,  0.7426]]],\n",
    "------------------------------------------------------------------\n",
    "\n",
    "quantized_features 1,249,256\n",
    "tensor([[[-0.0007,  0.0041,  0.0038,  ..., -0.0010,  0.0016,  0.0003],\n",
    "         [ 0.0035,  0.0055,  0.0023,  ...,  0.0107, -0.0053, -0.0056],\n",
    "         [-0.0015,  0.0167, -0.0020,  ..., -0.0018, -0.0030, -0.0007],\n",
    "         ...,\n",
    "         [ 0.0006, -0.0015, -0.0092,  ..., -0.0038,  0.0029,  0.0095],\n",
    "         [ 0.0033,  0.0141,  0.0015,  ..., -0.0038, -0.0048, -0.0006],\n",
    "         [ 0.0003, -0.0084, -0.0059,  ..., -0.0030, -0.0111, -0.0071]]]\n",
    "\n",
    "------------------------------------------------------------------<- into quantitation module\n",
    "\n",
    "hidden_states\n",
    "tensor([[[ 0.6000, -0.6655,  0.4842,  ..., -0.3797,  0.4714, -1.1692],\n",
    "         [ 0.2132, -0.8672,  0.2732,  ...,  0.2052,  0.5152,  0.3293],\n",
    "         [ 0.2438, -0.2918,  0.5199,  ..., -0.3120,  0.3674, -0.1998],\n",
    "         ...,\n",
    "         [ 0.7111,  0.0052, -0.3853,  ...,  0.0501, -0.6594,  0.5257],\n",
    "         [ 1.0093,  0.3563,  0.7620,  ..., -0.9669,  0.4358, -0.4640],\n",
    "         [ 0.8773, -0.3935, -0.9076,  ..., -0.9158,  0.4923,  0.1731]]],\n",
    "       device='cuda:0', grad_fn=<ViewBackward0>) torch.Size([1, 249, 640]) \n",
    "      \n",
    "tensor([[ 0.6000, -0.6655,  0.4842,  ...,  0.2033, -0.2749,  1.0719],<- then reshaped to this\n",
    "        [ 0.3865, -0.2972,  0.2173,  ..., -0.3797,  0.4714, -1.1692],\n",
    "        [ 0.2132, -0.8672,  0.2732,  ...,  0.4031,  0.8485,  0.5515],\n",
    "        ...,\n",
    "        [-0.1745,  0.4993, -0.1358,  ..., -0.9669,  0.4358, -0.4640],\n",
    "        [ 0.8773, -0.3935, -0.9076,  ...,  0.2689,  0.0802, -0.2527],\n",
    "        [ 0.1804,  0.3172, -0.1329,  ..., -0.9158,  0.4923,  0.1731]],\n",
    "       device='cuda:0', grad_fn=<ViewBackward0>) torch.Size([498, 320])\n",
    "\n",
    "------------------------------------------------------------------<- \n",
    "codevector_probs 498, 320\n",
    "\n",
    "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
    "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "        ...,\n",
    "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "        [0., 0., 0.,  ..., 0., 0., 0.]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
